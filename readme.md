批处理是企业级业务系统不可或缺的一部分，随着微服务化的系统越来越多，平台中有些耗时大批量的操作，特别是在excel文件的导入与导出，对系统的面临的考验越来越大，技术债务越来越重。

## 背景
为了解决大量导入导出经常导致应用系统内存耗尽而宕机，当时采用了异步排队，并且为每个应用系统分配一些内存较高的服务器来解决。但是并未解决所有的问题:<br/>
>业务反馈：
>>1. oms、ebill各自的导入导出“执行结果”页面，体验不好
>>2. 大数据量导出方案或功能，应对用户的特殊需求，三十万级，还是会出现内存、cpu占用过高情况；
>>3. 导出导出尽量不影响业务服务器（一旦崩了导致整个系统导出导出服务不可用）
***
>业务系统开发反馈：
>>1. 对业务系统要做好多事情（侵入性较大）
>>2. 有些任务框架上最好支持分片并行处理
>>3. 这个提供导入的方法本来就慢，针对这类任务最好框架上能限流或排队处理
***
>设计上的局限性：
>>1. 性能特别差，尽管采用定时任务排队执行解决，但时不时宕机
>>2. 系统资源浪费，并发一高时排队时间较长
>>3. 需要针对这些请求配置nginx转发，增加了运维复杂度
>>4. 对于大批量生成汇总类需求无力响应（需转发至报表，但有时候不是所有业务数据都希望被报表抽取）
>>5. 平台上微服务太多了，特别是DB拆分后不得不采用原来方案（集成，配置繁琐），上述问题更突出

## 设计须知
特别对上面的反馈有深刻领悟的同学，一般都知道：导入与导出的job非常特性，它不同于一般的job，它的批量有大有小，文件的格式个性化非常高。<p/>
独立出一个新系统（批处理服务引擎），进行数据的集中化管理，那它可以做什么？<p/>
-	性能好，支持一定数据的并发
-	能够对大批量数据进行抽取，分析处理，输出（目前定位在导入导出）
-	支持远程job，请求业务系统对数据进行处理，最终汇总到批处理服务器中
-	支持远程本地job，可以管理多个业务系统的数据源，同时支持不同数据源之间的同步（随着微服务越来越多这个不可少，接口毕竟解决不了这些问题）
-	任务分片要重点考虑：导入的分片在于切割文件，导出的分片在于分页
-	容错性，比如：导入一个批次失败不能代表整个job就是失败的（不可能全部回滚啊，要说服业务：支持的是滚动处理，能处理多少就多少进度很重要）
- 流控很重要，批处理服务和业务系统要保障它的可用性优先级是非常高的
-	集中化需考虑业务侵入性，原来应用的逻辑需迁移到新系统，需维护两处逻辑？需求是否多变？此处很关键


近期会开源
